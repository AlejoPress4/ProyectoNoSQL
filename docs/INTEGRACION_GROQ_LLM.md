# ü§ñ Integraci√≥n Groq LLM con RAG Multimodal

## Descripci√≥n General

Se ha integrado Groq LLM (modelo `llama-3.1-8b-instant`) en el sistema RAG para generar respuestas inteligentes basadas en el contexto recuperado de productos, im√°genes y rese√±as.

## üÜï Funcionalidades Implementadas

### 1. Cliente Groq (OpenAI Compatible)

```python
import os
from openai import OpenAI

client = OpenAI(
    api_key=os.environ.get("GROQ_API_KEY"),  # Configura esto en .env
    base_url="https://api.groq.com/openai/v1"
)
```

**Configuraci√≥n:**
- Variable de entorno: `GROQ_API_KEY` (opcional)
- Fallback: API key hardcodeada en el c√≥digo
- Modelo por defecto: `llama-3.1-8b-instant`

### 2. Generaci√≥n de Respuestas con LLM

**Funci√≥n:** `generate_answer_with_llm(context, question, model="llama-3.1-8b-instant")`

**Caracter√≠sticas:**
- ‚úÖ Prompt engineering optimizado para e-commerce tecnol√≥gico
- ‚úÖ Temperature: 0.4 (balanceo creatividad/precisi√≥n)
- ‚úÖ Max tokens: 800
- ‚úÖ Manejo de errores con fallback a respuesta b√°sica
- ‚úÖ Sistema prompt especializado en productos tech

**Ejemplo de uso:**
```python
context = build_context_for_llm_from_products(productos, max_items=6)
respuesta = generate_answer_with_llm(context, "¬øCu√°l es la mejor laptop para gaming?")
```

### 3. Construcci√≥n de Contexto Enriquecido

**Funci√≥n:** `build_context_for_llm_from_products(productos, max_items=6)`

**Incluye:**
- üìù Nombre, marca, precio, categor√≠a, descripci√≥n
- üîß Especificaciones t√©cnicas
- ‚≠ê Scores de similitud (text, image, hybrid)
- üëç Ventajas de rese√±as de usuarios
- üëé Desventajas de rese√±as de usuarios

**Formato del contexto:**
```
[PRODUCTO 1]
Nombre: Laptop Dell XPS 15
Marca: Dell
Precio: $1299.99 USD
Categor√≠a: Laptops
Descripci√≥n: Potente laptop con procesador Intel i7...
Especificaciones: RAM: 16GB, SSD: 512GB, GPU: RTX 3050
Relevancia: Text=85.3%, Image=78.2%, Hybrid=82.3%
    + Alto rendimiento
    + Excelente pantalla
    + Buena duraci√≥n de bater√≠a
    - Precio elevado
    - Ventiladores ruidosos
```

### 4. Visualizaci√≥n de Resultados (show_results)

**Funci√≥n:** `show_results(docs, fs)`

**Caracter√≠sticas:**
- üîé Muestra scores formateados
- üì∑ Renderiza im√°genes desde GridFS usando PIL
- üè∑Ô∏è Extrae metadatos (categor√≠a, tags, caption)
- ‚ö†Ô∏è Manejo robusto de errores en im√°genes

**Ejemplo de salida:**
```
üîé Dell XPS 15 | score=0.8523 | cat=Laptops | tags=['gaming', 'profesional']
  üì∑ Imagen cargada: (1920, 1080) px
```

### 5. Utilidades de Gesti√≥n de Metadatos

#### a) Actualizar Caption/Descripci√≥n

**Funci√≥n:** `update_caption_by_title(db, title, new_caption)`

**Endpoint:** `POST /api/utils/update-caption`

```bash
curl -X POST http://localhost:5000/api/utils/update-caption \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Dell XPS 15",
    "new_caption": "Laptop premium para profesionales creativos con pantalla 4K"
  }'
```

**Respuesta:**
```json
{
  "status": "success",
  "message": "Caption actualizado para: Dell XPS 15"
}
```

#### b) Eliminar Imagen y Metadatos

**Funci√≥n:** `delete_by_title(db, fs, title)`

**Endpoint:** `DELETE /api/utils/delete-image`

```bash
curl -X DELETE http://localhost:5000/api/utils/delete-image \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Producto obsoleto"
  }'
```

**Respuesta:**
```json
{
  "status": "success",
  "message": "Documento e imagen eliminados: Producto obsoleto"
}
```

#### c) Visualizar Resultados con Debugging

**Endpoint:** `POST /api/utils/show-results`

```bash
curl -X POST http://localhost:5000/api/utils/show-results \
  -H "Content-Type: application/json" \
  -d '{
    "query": "laptops gaming",
    "limit": 5
  }'
```

**Respuesta:**
```json
{
  "query": "laptops gaming",
  "results": [
    {
      "title": "Dell XPS 15",
      "score": "0.8523",
      "category": "Laptops",
      "tags": ["gaming", "profesional"],
      "caption": "Potente laptop...",
      "has_image": true
    }
  ],
  "total": 5
}
```

## üìä Endpoint RAG Actualizado

### POST /rag

**Flujo actualizado:**

1. **Generaci√≥n de embeddings**
   - Texto (sentence-transformers, 384d)
   - CLIP (para im√°genes, 512d)

2. **B√∫squeda multimodal**
   - Productos (texto)
   - Im√°genes (CLIP)
   - Rese√±as (texto)

3. **Fusi√≥n h√≠brida**
   - `hybrid_score = text_score * 0.6 + image_score * 0.4`

4. **Construcci√≥n de contexto enriquecido**
   - Productos con especificaciones
   - Ventajas/desventajas de rese√±as

5. **üÜï Generaci√≥n de respuesta con Groq LLM**
   - An√°lisis inteligente del contexto
   - Recomendaciones personalizadas
   - Comparaciones entre productos
   - Relaci√≥n calidad-precio

6. **Respuesta JSON**
   ```json
   {
     "query": "mejor laptop para gaming",
     "rag_response": "[RESPUESTA GENERADA POR LLM]",
     "productos": [...],
     "metadata": {
       "llm_used": true,
       "model_llm": "llama-3.1-8b-instant"
     }
   }
   ```

    ## üì¶ √çndices Vectoriales y Pipelines de B√∫squeda (Atlas Vector Search)

    Esta secci√≥n describe los √≠ndices vectoriales necesarios y ejemplos de pipelines `$vectorSearch` que implementa la aplicaci√≥n.

    Archivos de ejemplo con la definici√≥n de √≠ndices est√°n en `atlas_search_indexes/`:

    - `idx_descripcion_vector.json` (productos, `descripcion_embedding`, 384 dims)
    - `idx_imagen_vector_clip.json` (im√°genes, `imagen_embedding_clip`, 512 dims)
    - `idx_contenido_resena_vector.json` (rese√±as, `contenido_embedding`, 384 dims)

    Recomendaci√≥n: importa estos JSON en la secci√≥n "Search Indexes" de MongoDB Atlas para crear los √≠ndices. Aseg√∫rate de que `numDimensions` coincida con el tama√±o del vector (384 para text, 512 para CLIP).

    ### 1) Crear √≠ndices en Atlas (pasos r√°pidos)

    1. Abre tu cluster en MongoDB Atlas ‚Üí Search ‚Üí Create Search Index.
    2. Selecciona la colecci√≥n (ej. `productos`, `imagenesProducto`, `resenas`).
    3. Usa la opci√≥n "Import JSON" y pega el contenido de los archivos en `atlas_search_indexes/`.
    4. Guarda y espera a que Atlas construya el √≠ndice (puede tardar unos minutos).

    ### 2) Pipeline de ejemplo ‚Äî Productos (b√∫squeda por descripci√≥n)

    ```json
    [{
      "$vectorSearch": {
        "index": "idx_descripcion_vector",
        "path": "descripcion_embedding",
        "queryVector": /* aqu√≠ tu embedding de texto (lista) */,
        "numCandidates": 100,
        "limit": 10
      }
    }, {
      "$addFields": {"text_similarity": {"$meta": "vectorSearchScore"}}
    }, {
      "$project": {"nombre": 1, "marca_nombre": 1, "precio_usd": 1, "descripcion": 1, "text_similarity": 1}
    }]
    ```

    ### 3) Pipeline de ejemplo ‚Äî Im√°genes (CLIP)

    ```json
    [{
      "$vectorSearch": {
        "index": "idx_imagen_vector_clip",
        "path": "imagen_embedding_clip",
        "queryVector": /* embedding CLIP (512 dims) */,
        "numCandidates": 200,
        "limit": 20
      }
    }, {
      "$addFields": {"image_similarity": {"$meta": "vectorSearchScore"}}
    }, {
      "$project": {"codigo_producto": 1, "imagen_url": 1, "texto_alternativo": 1, "image_similarity": 1}
    }]
    ```

    ### 4) Pipeline de ejemplo ‚Äî Rese√±as

    ```json
    [{
      "$vectorSearch": {
        "index": "idx_contenido_resena_vector",
        "path": "contenido_embedding",
        "queryVector": /* embedding de texto (384 dims) */,
        "numCandidates": 200,
        "limit": 10
      }
    }, {
      "$addFields": {"review_similarity": {"$meta": "vectorSearchScore"}}
    }, {
      "$project": {"codigo_producto": 1, "titulo": 1, "contenido": 1, "calificacion": 1, "review_similarity": 1}
    }]
    ```

    ### 5) Fallback cuando Atlas Vector Search no est√° disponible

    Si no puedes usar `$vectorSearch` (por ejemplo en entornos locales o si los √≠ndices no existen), la aplicaci√≥n ofrece un fallback que:

    - Calcula similitud coseno localmente usando `sklearn.metrics.pairwise.cosine_similarity` entre tu embedding y embeddings almacenados en la colecci√≥n.
    - Aplica filtros (categor√≠a, marca, precio) y ordena por similitud.

    Ejemplo (pseudo-code Python):

    ```python
    from sklearn.metrics.pairwise import cosine_similarity
    query_emb = generate_embedding(query_text)  # 384d
    docs = list(db['productos'].find({'descripcion_embedding': {'$exists': True}}))
    scores = []
    for d in docs:
        v = d['descripcion_embedding']
        s = float(cosine_similarity([query_emb], [v])[0][0])
        scores.append((s, d))
    top = sorted(scores, key=lambda x: x[0], reverse=True)[:10]
    ```

    ### 6) Verificar que los embeddings existen (comandos √∫tiles)

    En una sesi√≥n Python (o en `scripts/`):

    ```python
    db = get_database()
    print('Productos con embedding:', db['productos'].count_documents({'descripcion_embedding': {'$exists': True}}))
    print('Im√°genes con CLIP emb:', db['imagenesProducto'].count_documents({'imagen_embedding_clip': {'$exists': True}}))
    print('Rese√±as con embedding:', db['resenas'].count_documents({'contenido_embedding': {'$exists': True}}))
    ```

    Si los conteos son 0 para im√°genes, debes generar embeddings CLIP; hay un script en `scripts/generate_image_embeddings_clip.py`.

    ### 7) Generar embeddings (resumen r√°pido)

    - Embeddings de texto: `scripts/load_data.py` o `scripts/generate_text_embeddings.py` (seg√∫n tu repo) ‚Äî usa `sentence-transformers` (384d).
    - Embeddings de im√°genes CLIP: `scripts/generate_image_embeddings_clip.py` ‚Äî usa `openai/clip-vit-base-patch32` y guarda los vectores en `imagen_embedding_clip` (512d).

    Ejemplo para ejecutar el script de im√°genes:

    ```powershell
    py scripts\generate_image_embeddings_clip.py
    ```

    ### 8) Validaci√≥n de dimensionalidad

    Antes de crear √≠ndices, valida la dimensi√≥n de los vectores guardados:

    ```python
    sample = db['imagenesProducto'].find_one({'imagen_embedding_clip': {'$exists': True}})
    len(sample['imagen_embedding_clip'])  # debe ser 512
    ```

    ### 9) Logs y debugging

    - El servidor registra cu√°ntas im√°genes con embeddings encuentra al arrancar y cuando se ejecutan b√∫squedas.
    - Si ves `0` im√°genes con embeddings, ejecuta el script de generaci√≥n y vuelve a importar el √≠ndice en Atlas.

    ---

    Con esto, la aplicaci√≥n podr√° ejecutar correctamente las tres b√∫squedas vectoriales y fusionarlas para obtener resultados multimodales. Si quieres, implemento un script adicional que valide los √≠ndices en Atlas v√≠a la API (o que intente crear los √≠ndices autom√°ticamente con la Admin API). ¬øQu√© prefieres que haga ahora: (A) a√±adir un script para crear √≠ndices autom√°ticamente, o (B) documentar el proceso paso a paso para importarlos manualmente en Atlas?

**Ejemplo de consulta:**
```bash
curl -X POST http://localhost:5000/rag \
  -H "Content-Type: application/json" \
  -d '{
    "query": "laptop gaming con buena refrigeraci√≥n bajo $1500",
    "max_products": 5,
    "include_reviews": true,
    "include_images": true
  }'
```

**Respuesta del LLM (ejemplo):**

> Bas√°ndome en el contexto recuperado, te recomiendo las siguientes opciones:
> 
> **1. Dell XPS 15 ($1299.99)**
> - Excelente sistema de refrigeraci√≥n con ventiladores duales
> - GPU RTX 3050 ideal para gaming 1080p
> - Los usuarios destacan: "Alto rendimiento", "Buena duraci√≥n de bater√≠a"
> - Contras: Ventiladores pueden ser ruidosos bajo carga extrema
> 
> **2. ASUS ROG Strix G15 ($1449.99)**
> - Sistema de refrigeraci√≥n ROG con l√≠quido y vapor chamber
> - GPU RTX 3060, mejor que la XPS para gaming intensivo
> - Ventajas seg√∫n rese√±as: "Excelente refrigeraci√≥n", "Alto FPS en juegos"
> - Contras: Dise√±o gaming muy llamativo, no ideal para oficina
> 
> **Recomendaci√≥n:** Si priorizas refrigeraci√≥n, la ASUS ROG ofrece mejor sistema de cooling. Si buscas balance entre trabajo/gaming, la Dell XPS es m√°s vers√°til.

## üéØ Ventajas de la Integraci√≥n LLM

1. **Respuestas naturales y conversacionales**
   - No m√°s plantillas r√≠gidas
   - An√°lisis contextual profundo

2. **Comparaciones inteligentes**
   - Detecta trade-offs autom√°ticamente
   - Sugiere seg√∫n necesidades del usuario

3. **Interpretaci√≥n de rese√±as**
   - Sintetiza ventajas/desventajas
   - Identifica patrones en opiniones

4. **Personalizaci√≥n**
   - Adapta lenguaje seg√∫n consulta
   - Prioriza caracter√≠sticas relevantes

5. **Fallback robusto**
   - Si LLM falla, usa respuesta b√°sica
   - No interrumpe la experiencia del usuario

## üîí Seguridad y Mejores Pr√°cticas

1. **API Key Management**
   ```python
   # Usar variable de entorno en producci√≥n
   api_key = os.environ.get("GROQ_API_KEY", "fallback_key")
   ```

2. **Rate Limiting**
   - Groq: l√≠mite de requests/minuto
   - Implementar cach√© de respuestas frecuentes

3. **Validaci√≥n de contexto**
   - M√°ximo 6 productos para no exceder tokens
   - Truncar descripciones muy largas

4. **Monitoreo**
   ```python
   print(f"‚úì Respuesta LLM generada: {len(respuesta)} caracteres")
   ```

## üöÄ Pr√≥ximos Pasos

- [ ] Implementar cach√© de respuestas LLM (Redis)
- [ ] Agregar modelo de fallback (GPT-3.5-turbo)
- [ ] A/B testing: respuestas LLM vs respuestas template
- [ ] M√©tricas: tiempo de respuesta, tasa de √©xito
- [ ] Fine-tuning de prompts basado en feedback

## üìö Referencias

- [Groq API Docs](https://console.groq.com/docs)
- [OpenAI Python Client](https://github.com/openai/openai-python)
- [LLama 3.1 Model Card](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct)

---

**√öltima actualizaci√≥n:** 3 de diciembre de 2025
**Versi√≥n:** 2.0 - RAG Multimodal + Groq LLM
